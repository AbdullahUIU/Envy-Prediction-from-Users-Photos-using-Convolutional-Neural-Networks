{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd0bbc90",
   "metadata": {},
   "source": [
    "In this study, we will be showcasing a computer vision classification problem using photos to predict envy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981a133",
   "metadata": {},
   "source": [
    "# Optimal Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9fc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,Flatten,Dense,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "\n",
    "#Directories\n",
    "\n",
    "train_path = r\"E:\\EnvySplit\\train\"\n",
    "val_path = r\"E:\\EnvySplit\\val\"\n",
    "test_path = r\"E:\\EnvySplit\\test\"\n",
    "\n",
    "\n",
    "model=tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(filters=64,padding='same',strides=2,kernel_size=3,activation='relu',input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size =2, strides=2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size =2, strides=2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=32,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size =2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16,padding='same',strides=2,kernel_size=3,activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size =2))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(2,activation=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   vertical_flip= True)\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224,224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical')\n",
    "val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                            target_size = (224,224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224,224),\n",
    "                                            batch_size = 1,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "op = keras.optimizers.Adam(learning_rate=0.001)  \n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=op,\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "filepath = \"D:\\Envy2\\Weights\\EnvyPre150epochsRGBBatch16LR0.0001relu.h5\"\n",
    "\n",
    "\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_weights_only=True,\n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "log_csv = CSVLogger('D:\\Envy2\\CSVlogger\\EnvyPre150epochsRGBBatch16LR0.0001relu.csv', separator=',', append=False)\n",
    " \n",
    "    \n",
    "callbacks_list = [checkpoint1,log_csv]\n",
    "\n",
    "\n",
    "r = model.fit_generator(\n",
    "    training_set,\n",
    "    epochs=150,\n",
    "    validation_data=val_set,\n",
    "    steps_per_epoch = len(training_set),\n",
    "    validation_steps=len(val_set),\n",
    "    callbacks=callbacks_list,\n",
    "    shuffle=False\n",
    "    \n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
